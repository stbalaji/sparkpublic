{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMj6+amdY73Rgiaxrrtmz2D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stbalaji/sparkpublic/blob/main/sparkClusterSubmit02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVpz9mduIo1Y"
      },
      "source": [
        "# install Java8\r\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6tJvmiAJdbb"
      },
      "source": [
        "# download spark3.0.0\r\n",
        "!wget -q http://apache.osuosl.org/spark/spark-3.0.1/spark-3.0.1-bin-hadoop3.2.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZh42Sr_Jir0"
      },
      "source": [
        "# unzip it\r\n",
        "!tar xf spark-3.0.1-bin-hadoop3.2.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nUJeg1VKoTE"
      },
      "source": [
        "# install findspark \r\n",
        "!pip install -q findspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgMR65drKtj6"
      },
      "source": [
        "import os\r\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\r\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.1-bin-hadoop3.2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u11S8i8WK4-6",
        "outputId": "14cca0ce-707b-4dc4-ec9a-ce0d7883f6f8"
      },
      "source": [
        "import findspark\r\n",
        "findspark.init()\r\n",
        "\r\n",
        "from pyspark.sql import SparkSession\r\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\r\n",
        "# Test the spark\r\n",
        "df = spark.createDataFrame([{\"hello\": \"world\"} for x in range(1000)])\r\n",
        "df.show(3, False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/session.py:381: UserWarning: inferring schema from dict is deprecated,please use pyspark.sql.Row instead\n",
            "  warnings.warn(\"inferring schema from dict is deprecated,\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "+-----+\n",
            "|hello|\n",
            "+-----+\n",
            "|world|\n",
            "|world|\n",
            "|world|\n",
            "+-----+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "defeHrfsLF2C",
        "outputId": "356a5b6a-aa50-4b68-b271-b758105d96c9"
      },
      "source": [
        "# Check the pyspark version\r\n",
        "import pyspark\r\n",
        "print(pyspark.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unSl1JkgLRwD",
        "outputId": "30861eec-5ffc-4e34-ddd8-27ed6b4ce3bc"
      },
      "source": [
        "!ls -la"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 218832\n",
            "drwxr-xr-x  1 root root      4096 Feb  5 17:08 .\n",
            "drwxr-xr-x  1 root root      4096 Feb  5 17:00 ..\n",
            "drwxr-xr-x  1 root root      4096 Feb  4 15:26 .config\n",
            "drwxr-xr-x  1 root root      4096 Feb  4 15:26 sample_data\n",
            "drwxr-xr-x 13 1000 1000      4096 Aug 28 09:22 spark-3.0.1-bin-hadoop3.2\n",
            "-rw-r--r--  1 root root 224062525 Aug 28 09:25 spark-3.0.1-bin-hadoop3.2.tgz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMmCvl0CL_Fj"
      },
      "source": [
        "from pyspark.sql import SparkSession\r\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "eF6ttC5zMCUZ",
        "outputId": "d0752f82-f00b-4e37-c020-de10d6578b7b"
      },
      "source": [
        "spark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://7510fbc9e2de:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.0.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f75c78ce6a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MRysw5aMMLi",
        "outputId": "74bdf07f-48b2-491e-d9e6-ec53f8813052"
      },
      "source": [
        "print(os.listdir('./sample_data'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['README.md', 'anscombe.json', 'california_housing_train.csv', 'california_housing_test.csv', 'mnist_train_small.csv', 'mnist_test.csv']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z74fs24sM43i",
        "outputId": "8f9a5c77-615f-4c3c-be80-6a5c7dccd85a"
      },
      "source": [
        "#print(os.listdir('./sample_data'))\r\n",
        "file_loc = \"./sample_data/california_housing_train.csv\"\r\n",
        "df_spark = spark.read.csv(file_loc, inferSchema=True, header=True)\r\n",
        "print(type(df_spark))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pyspark.sql.dataframe.DataFrame'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6s-eYQZNPWi",
        "outputId": "850f9b6f-2510-42e3-f052-72ef5c57f20c"
      },
      "source": [
        "df_spark.show(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|  -114.31|   34.19|              15.0|     5612.0|        1283.0|    1015.0|     472.0|       1.4936|           66900.0|\n",
            "|  -114.47|    34.4|              19.0|     7650.0|        1901.0|    1129.0|     463.0|         1.82|           80100.0|\n",
            "|  -114.56|   33.69|              17.0|      720.0|         174.0|     333.0|     117.0|       1.6509|           85700.0|\n",
            "|  -114.57|   33.64|              14.0|     1501.0|         337.0|     515.0|     226.0|       3.1917|           73400.0|\n",
            "|  -114.57|   33.57|              20.0|     1454.0|         326.0|     624.0|     262.0|        1.925|           65500.0|\n",
            "|  -114.58|   33.63|              29.0|     1387.0|         236.0|     671.0|     239.0|       3.3438|           74000.0|\n",
            "|  -114.58|   33.61|              25.0|     2907.0|         680.0|    1841.0|     633.0|       2.6768|           82400.0|\n",
            "|  -114.59|   34.83|              41.0|      812.0|         168.0|     375.0|     158.0|       1.7083|           48500.0|\n",
            "|  -114.59|   33.61|              34.0|     4789.0|        1175.0|    3134.0|    1056.0|       2.1782|           58400.0|\n",
            "|   -114.6|   34.83|              46.0|     1497.0|         309.0|     787.0|     271.0|       2.1908|           48100.0|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNBfpJhqPxV7"
      },
      "source": [
        "!wget -q  http://www.grouplens.org/system/files/ml-100k.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mX-GDttSvix"
      },
      "source": [
        "!unzip ml-100k.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BMkbFVYQRgQ",
        "outputId": "96d35ac5-aeee-4721-c9f3-c19ffaac65b9"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YylQ_43IVeOQ"
      },
      "source": [
        "from pyspark.sql.types import StringType, IntegerType, TimestampType, StructType, StructField\r\n",
        "  # cols = ['user_id', 'item_id', 'rating','timestamp']\r\n",
        "schema = StructType([StructField('userid', IntegerType(), True),\r\n",
        "                     StructField('movieId', IntegerType(), True),\r\n",
        "                     StructField('rating', IntegerType(), True),\r\n",
        "                     StructField('timestamp', TimestampType(), True)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bsawddPUVQB",
        "outputId": "4a16e486-5d1b-4fbd-ebac-0077eadd096e"
      },
      "source": [
        "from pyspark.sql import SparkSession\r\n",
        "from pyspark.sql.functions import *\r\n",
        "from pyspark.sql import SQLContext\r\n",
        "\r\n",
        "import operator\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "\r\n",
        "    spark = SparkSession.builder.appName(\"LessonOnClusterComputingMovielens\").getOrCreate()\r\n",
        "    v_sc = spark.sparkContext\r\n",
        "\r\n",
        "    # cols = ['user_id', 'item_id', 'rating','timestamp']\r\n",
        "    filepath = \"./ml-100k/\"\r\n",
        "\r\n",
        "    # Create a dataframe\r\n",
        "    dataFrameReader = spark.read\r\n",
        "    df_ratings = dataFrameReader.format(\"CSV\").option(\"delimiter\", \"\\t\").option(\"header\",\"false\").schema(schema).load(filepath + \"u.data\")\r\n",
        "    #df_movies = dataFrameReader.format(\"CSV\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").load(filepath + \"movies.csv\")\r\n",
        "\r\n",
        "    print(\"=== Here is Schema of Ratings Data ===\")\r\n",
        "    df_ratings.printSchema()\r\n",
        "\r\n",
        "    print(\"=== Total number of Ratings === : \", df_ratings.count())\r\n",
        "    \r\n",
        "    df_ratings_subset = df_ratings.select(\"userId\", \"movieId\", \"rating\")  # Timestamp may not be needed for now\r\n",
        "    print(\"=== Ratings with only Selected Columns === : \")\r\n",
        "    df_ratings_subset.show()\r\n",
        "    \r\n",
        "    df_ratings_subset = df_ratings.select(\"userId\", \"movieId\", \"rating\")  # Timestamp may not be needed for now\r\n",
        "    print(\"=== Ratings with only Selected Columns === : \")\r\n",
        "    df_ratings_subset.show()\r\n",
        "\r\n",
        "    print(\"=== Print all the ratings for a particular Movie ===\")\r\n",
        "    df_ratings_subset.filter(df_ratings_subset.movieId == 100).show()\r\n",
        "\r\n",
        "    #find unique values of a ratings\r\n",
        "    print(\"=== Print all the ratings for a particular Movie ===\")\r\n",
        "    ratings_1 = df_ratings_subset.toPandas()['rating'].unique()\r\n",
        "    ratings_1\r\n",
        "\r\n",
        "    ratings_2 = df_ratings.select('rating').distinct().collect()\r\n",
        "    ratings_2\r\n",
        "\r\n",
        "    print(\"=== Print the count of ratings ===\")\r\n",
        "    groupedRatings = df_ratings.groupby('rating')\r\n",
        "    groupedRatings.count().show()\r\n",
        "\r\n",
        "    df_ratings_subset.groupby('rating').count().orderBy(\"rating\").show()\r\n",
        "\r\n",
        "    print(\"=== Print ratings by their counts in the descenting order ===\")\r\n",
        "    import pyspark.sql.functions as f\r\n",
        "    groupedRatings.count().select('rating', f.col('count').alias('numOfRatings')).orderBy(\"numOfRatings\", ascending=False).show()\r\n",
        "\r\n",
        "    print(\"=== Print top 10 movies by number of ratings ===\")\r\n",
        "    groupedMovies = df_ratings.groupby('movieId')\r\n",
        "    groupedMovies.count().select('movieId', f.col('count').alias('numOfRatings')).orderBy(\"numOfRatings\", ascending=False).show(10)\r\n",
        "\r\n",
        "    print(\"=== Exiting the code ===\")\r\n",
        "\r\n",
        "    spark.stop()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== Here is Schema of Ratings Data ===\n",
            "root\n",
            " |-- userid: integer (nullable = true)\n",
            " |-- movieId: integer (nullable = true)\n",
            " |-- rating: integer (nullable = true)\n",
            " |-- timestamp: timestamp (nullable = true)\n",
            "\n",
            "=== Total number of Ratings === :  100000\n",
            "=== Ratings with only Selected Columns === : \n",
            "+------+-------+------+\n",
            "|userId|movieId|rating|\n",
            "+------+-------+------+\n",
            "|   196|    242|     3|\n",
            "|   186|    302|     3|\n",
            "|    22|    377|     1|\n",
            "|   244|     51|     2|\n",
            "|   166|    346|     1|\n",
            "|   298|    474|     4|\n",
            "|   115|    265|     2|\n",
            "|   253|    465|     5|\n",
            "|   305|    451|     3|\n",
            "|     6|     86|     3|\n",
            "|    62|    257|     2|\n",
            "|   286|   1014|     5|\n",
            "|   200|    222|     5|\n",
            "|   210|     40|     3|\n",
            "|   224|     29|     3|\n",
            "|   303|    785|     3|\n",
            "|   122|    387|     5|\n",
            "|   194|    274|     2|\n",
            "|   291|   1042|     4|\n",
            "|   234|   1184|     2|\n",
            "+------+-------+------+\n",
            "only showing top 20 rows\n",
            "\n",
            "=== Ratings with only Selected Columns === : \n",
            "+------+-------+------+\n",
            "|userId|movieId|rating|\n",
            "+------+-------+------+\n",
            "|   196|    242|     3|\n",
            "|   186|    302|     3|\n",
            "|    22|    377|     1|\n",
            "|   244|     51|     2|\n",
            "|   166|    346|     1|\n",
            "|   298|    474|     4|\n",
            "|   115|    265|     2|\n",
            "|   253|    465|     5|\n",
            "|   305|    451|     3|\n",
            "|     6|     86|     3|\n",
            "|    62|    257|     2|\n",
            "|   286|   1014|     5|\n",
            "|   200|    222|     5|\n",
            "|   210|     40|     3|\n",
            "|   224|     29|     3|\n",
            "|   303|    785|     3|\n",
            "|   122|    387|     5|\n",
            "|   194|    274|     2|\n",
            "|   291|   1042|     4|\n",
            "|   234|   1184|     2|\n",
            "+------+-------+------+\n",
            "only showing top 20 rows\n",
            "\n",
            "=== Print all the ratings for a particular Movie ===\n",
            "+------+-------+------+\n",
            "|userId|movieId|rating|\n",
            "+------+-------+------+\n",
            "|   251|    100|     4|\n",
            "|    10|    100|     5|\n",
            "|   108|    100|     4|\n",
            "|    63|    100|     5|\n",
            "|   312|    100|     4|\n",
            "|    65|    100|     3|\n",
            "|    79|    100|     5|\n",
            "|    58|    100|     5|\n",
            "|   198|    100|     1|\n",
            "|   184|    100|     5|\n",
            "|   131|    100|     5|\n",
            "|   150|    100|     2|\n",
            "|   307|    100|     3|\n",
            "|   109|    100|     4|\n",
            "|   237|    100|     5|\n",
            "|   329|    100|     4|\n",
            "|   244|    100|     4|\n",
            "|   195|    100|     5|\n",
            "|   292|    100|     5|\n",
            "|   286|    100|     3|\n",
            "+------+-------+------+\n",
            "only showing top 20 rows\n",
            "\n",
            "=== Print all the ratings for a particular Movie ===\n",
            "=== Print the count of ratings ===\n",
            "+------+-----+\n",
            "|rating|count|\n",
            "+------+-----+\n",
            "|     1| 6110|\n",
            "|     3|27145|\n",
            "|     5|21201|\n",
            "|     4|34174|\n",
            "|     2|11370|\n",
            "+------+-----+\n",
            "\n",
            "+------+-----+\n",
            "|rating|count|\n",
            "+------+-----+\n",
            "|     1| 6110|\n",
            "|     2|11370|\n",
            "|     3|27145|\n",
            "|     4|34174|\n",
            "|     5|21201|\n",
            "+------+-----+\n",
            "\n",
            "=== Print ratings by their counts in the descenting order ===\n",
            "+------+------------+\n",
            "|rating|numOfRatings|\n",
            "+------+------------+\n",
            "|     4|       34174|\n",
            "|     3|       27145|\n",
            "|     5|       21201|\n",
            "|     2|       11370|\n",
            "|     1|        6110|\n",
            "+------+------------+\n",
            "\n",
            "=== Print top 10 movies by number of ratings ===\n",
            "+-------+------------+\n",
            "|movieId|numOfRatings|\n",
            "+-------+------------+\n",
            "|     50|         583|\n",
            "|    258|         509|\n",
            "|    100|         508|\n",
            "|    181|         507|\n",
            "|    294|         485|\n",
            "|    286|         481|\n",
            "|    288|         478|\n",
            "|      1|         452|\n",
            "|    300|         431|\n",
            "|    121|         429|\n",
            "+-------+------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "=== Exiting the code ===\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEnUwjbgaa33",
        "outputId": "d9c8d8be-0f56-4a2c-805c-1bb27d24f68e"
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\r\n",
        "!unzip ngrok-stable-linux-amd64.zip\r\n",
        "get_ipython().system_raw('./ngrok http 4050 &')\r\n",
        "!curl -s http://localhost:4040/api/tunnels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-05 18:32:11--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 54.204.23.149, 34.193.233.154, 3.226.231.47, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|54.204.23.149|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.1’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.13M  13.9MB/s    in 0.9s    \n",
            "\n",
            "2021-02-05 18:32:12 (13.9 MB/s) - ‘ngrok-stable-linux-amd64.zip.1’ saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: ngrok                   \n",
            "{\"tunnels\":[{\"name\":\"command_line\",\"uri\":\"/api/tunnels/command_line\",\"public_url\":\"https://13c5258afc6f.ngrok.io\",\"proto\":\"https\",\"config\":{\"addr\":\"http://localhost:4050\",\"inspect\":true},\"metrics\":{\"conns\":{\"count\":6,\"gauge\":0,\"rate1\":5.965349913224447e-8,\"rate5\":0.0011352891050691314,\"rate15\":0.002561786855325972,\"p50\":1793135.5,\"p90\":3203751,\"p95\":3203751,\"p99\":3203751},\"http\":{\"count\":6,\"rate1\":5.965349913224447e-8,\"rate5\":0.0011352891050691314,\"rate15\":0.002561786855325972,\"p50\":774109,\"p90\":2384270,\"p95\":2384270,\"p99\":2384270}}},{\"name\":\"command_line (http)\",\"uri\":\"/api/tunnels/command_line%20%28http%29\",\"public_url\":\"http://13c5258afc6f.ngrok.io\",\"proto\":\"http\",\"config\":{\"addr\":\"http://localhost:4050\",\"inspect\":true},\"metrics\":{\"conns\":{\"count\":0,\"gauge\":0,\"rate1\":0,\"rate5\":0,\"rate15\":0,\"p50\":0,\"p90\":0,\"p95\":0,\"p99\":0},\"http\":{\"count\":0,\"rate1\":0,\"rate5\":0,\"rate15\":0,\"p50\":0,\"p90\":0,\"p95\":0,\"p99\":0}}}],\"uri\":\"/api/tunnels\"}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eUHdCJ8gUCu",
        "outputId": "06030d4b-598d-45fa-8018-f04b5ff188a9"
      },
      "source": [
        "# Install useful stuff\r\n",
        "! apt install --yes ssh screen nano htop ranger git > /dev/null# SSH setting\r\n",
        "! echo \"root:carbonara\" | chpasswd\r\n",
        "! echo \"PasswordAuthentication yes\" > /etc/ssh/sshd_config\r\n",
        "! echo \"PermitUserEnvironment yes\" >> /etc/ssh/sshd_config\r\n",
        "! echo \"PermitRootLogin yes\" >> /etc/ssh/sshd_config\r\n",
        "! service ssh restart > /dev/null# Download ngrok\r\n",
        "! wget -q -c -nc https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\r\n",
        "! unzip -qq -n ngrok-stable-linux-amd64.zip# Run ngrok\r\n",
        "authtoken = \"1o4fP2v3NWaVtuedLz5FFjuVMDu_5CMQDiEfxBxKbgvfnw2vW\"\r\n",
        "get_ipython().system_raw('./ngrok authtoken $authtoken && ./ngrok tcp 22 &')\r\n",
        "! sleep 3# Get the address for SSH\r\n",
        "import requests\r\n",
        "from re import sub\r\n",
        "r = requests.get('http://localhost:4040/api/tunnels')\r\n",
        "str_ssh = r.json()['tunnels'][0]['public_url']\r\n",
        "str_ssh = sub(\"tcp://\", \"\", str_ssh)\r\n",
        "str_ssh = sub(\":\", \" -p \", str_ssh)\r\n",
        "str_ssh = \"ssh root@\" + str_ssh\r\n",
        "print(str_ssh)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "E: Unable to locate package SSH\n",
            "E: Unable to locate package setting\n",
            "ssh: unrecognized service\n",
            "unzip:  cannot find or open ngrok-stable-linux-amd64.zip#, ngrok-stable-linux-amd64.zip#.zip or ngrok-stable-linux-amd64.zip#.ZIP.\n",
            "sleep: invalid time interval ‘3#’\n",
            "sleep: invalid time interval ‘Get’\n",
            "sleep: invalid time interval ‘the’\n",
            "sleep: invalid time interval ‘address’\n",
            "sleep: invalid time interval ‘for’\n",
            "sleep: invalid time interval ‘SSH’\n",
            "Try 'sleep --help' for more information.\n",
            "ssh root@https -p //13c5258afc6f.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}